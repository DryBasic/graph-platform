{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load topic-keyword associations generated from NLP methods.\n",
    "\n",
    "Pivots to general schema wherein each record is a topic-keyword association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = pd.read_csv('../raw/lyrics_topics_terms.csv')[['topic_id', 'term_1_word', 'term_1_probability',\n",
    "       'term_2_word', 'term_2_probability', 'term_3_word',\n",
    "       'term_3_probability', 'term_4_word', 'term_4_probability',\n",
    "       'term_5_word', 'term_5_probability', 'term_6_word',\n",
    "       'term_6_probability', 'term_7_word', 'term_7_probability',\n",
    "       'term_8_word', 'term_8_probability', 'term_9_word',\n",
    "       'term_9_probability', 'term_10_word', 'term_10_probability',\n",
    "       'term_11_word', 'term_11_probability', 'term_12_word',\n",
    "       'term_12_probability', 'term_13_word', 'term_13_probability',\n",
    "       'term_14_word', 'term_14_probability', 'term_15_word',\n",
    "       'term_15_probability']]\n",
    "\n",
    "pairs = list(chunks(list(topic_word.columns[1:]), 2))\n",
    "\n",
    "pieces = []\n",
    "for pair in pairs:\n",
    "    subset = topic_word[['topic_id']+pair].rename(columns={\n",
    "        pair[0]: 'word',\n",
    "        pair[1]: 'probability'\n",
    "    })\n",
    "    pieces.append(subset)\n",
    "\n",
    "tall = pd.concat(pieces)\n",
    "\n",
    "tall.to_csv('../clean/edge_word_topic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following topic names were generated with inspiration by ChatGPT prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    " 'Explicit',\n",
    " 'Romantic Country',\n",
    " 'Spanish/time of day?',\n",
    " 'Heartbreak',\n",
    " 'Aggressive Romance',\n",
    " 'Crime',\n",
    " 'General verbs',\n",
    " 'Movement',\n",
    " 'Alcohol',\n",
    " 'Breakup/Leaving',\n",
    " 'Magical/Fantasy',\n",
    " 'Sensual Spanish',\n",
    " 'Mad at boy',\n",
    " 'Nostalgia',\n",
    " 'Physical Appearance',\n",
    " 'Hip Hop Romance',\n",
    " 'Wistful Romance',\n",
    " 'Upbeat Dance',\n",
    " 'Rebellious',\n",
    " 'Weather'\n",
    "]\n",
    "pd.DataFrame(topics, columns=['topic']).to_csv('../clean/node_topic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
