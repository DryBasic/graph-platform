{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load topic-keyword associations generated from NLP methods.\n",
    "\n",
    "Pivots to general schema wherein each record is a topic-keyword association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = pd.read_csv('../raw/lyrics_topics_terms.csv')[['topic_id', 'term_1_word', 'term_1_probability',\n",
    "       'term_2_word', 'term_2_probability', 'term_3_word',\n",
    "       'term_3_probability', 'term_4_word', 'term_4_probability',\n",
    "       'term_5_word', 'term_5_probability', 'term_6_word',\n",
    "       'term_6_probability', 'term_7_word', 'term_7_probability',\n",
    "       'term_8_word', 'term_8_probability', 'term_9_word',\n",
    "       'term_9_probability', 'term_10_word', 'term_10_probability',\n",
    "       'term_11_word', 'term_11_probability', 'term_12_word',\n",
    "       'term_12_probability', 'term_13_word', 'term_13_probability',\n",
    "       'term_14_word', 'term_14_probability', 'term_15_word',\n",
    "       'term_15_probability']]\n",
    "\n",
    "pairs = list(chunks(list(topic_word.columns[1:]), 2))\n",
    "\n",
    "pieces = []\n",
    "for pair in pairs:\n",
    "    subset = topic_word[['topic_id']+pair].rename(columns={\n",
    "        pair[0]: 'word',\n",
    "        pair[1]: 'probability'\n",
    "    })\n",
    "    pieces.append(subset)\n",
    "\n",
    "tall = pd.concat(pieces)\n",
    "\n",
    "tall.to_csv('../clean/edge_word_topic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following topic names were generated with inspiration by ChatGPT prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "    [0, 'Dance Party'],\n",
    "    [1, 'Sensory Fusion + Spanish)'],\n",
    "    [2, 'Emotional Timeframe'],\n",
    "    [3, 'French Countryside Summer'],\n",
    "    [4, 'Spirituality + Spanish'],\n",
    "    [5, 'Revolution + Spanish'],\n",
    "    [6, 'Twilight Narratives'],\n",
    "    [7, 'Sensory Spanish'],\n",
    "    [8, 'Country Daydream (Names)'],\n",
    "    [9, 'Emotional Outburst (Explicit)'],\n",
    "    [10, 'Dale'],\n",
    "    [11, 'Doja'],\n",
    "    [12, 'Relations (Spanish)'],\n",
    "    [13, 'Lil Blossom'],\n",
    "    [14, 'Troubled Tunes'],\n",
    "    [15, 'Nightlife'],\n",
    "    [16, 'Eloquent'],\n",
    "    [17, 'Ticket to Tenderness'],\n",
    "    [18, 'Diste la Verdad'],\n",
    "    [19, 'Watermelon Sugar']\n",
    "]\n",
    "# pd.read_csv('../raw/track_keyword_occurences.csv').dropna()[['sid','word', 'occurence']].to_csv('../clean/edge_word_track.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
