{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.read_csv('../clean/node_feature.csv')\n",
    "trackf = pd.read_csv('encoded_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
    "       'valence', 'tempo', 'duration_ms', 'time_signature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_dfs = []\n",
    "for feature in features:\n",
    "    subset = trackf[['spotify_id', feature]].rename(columns={feature: 'value'})\n",
    "    subset['feature_name'] = feature\n",
    "    subset['encoded_value'] = trackf[feature+'_encoded']\n",
    "    union_dfs.append(subset)\n",
    "\n",
    "tall = pd.concat(union_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = tall.rename(columns={'feature_name': 'feature', 'encoded_value': 'encoding'}).set_index(['feature', 'encoding']).join(fdf.set_index(['feature', 'encoding'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('../clean/edge_track_feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = pd.read_csv('../raw/lyrics_topics_terms.csv')[['topic_id', 'term_1_word', 'term_1_probability',\n",
    "       'term_2_word', 'term_2_probability', 'term_3_word',\n",
    "       'term_3_probability', 'term_4_word', 'term_4_probability',\n",
    "       'term_5_word', 'term_5_probability', 'term_6_word',\n",
    "       'term_6_probability', 'term_7_word', 'term_7_probability',\n",
    "       'term_8_word', 'term_8_probability', 'term_9_word',\n",
    "       'term_9_probability', 'term_10_word', 'term_10_probability',\n",
    "       'term_11_word', 'term_11_probability', 'term_12_word',\n",
    "       'term_12_probability', 'term_13_word', 'term_13_probability',\n",
    "       'term_14_word', 'term_14_probability', 'term_15_word',\n",
    "       'term_15_probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(chunks(list(topic_word.columns[1:]), 2))\n",
    "\n",
    "pieces = []\n",
    "for pair in pairs:\n",
    "    subset = topic_word[['topic_id']+pair].rename(columns={\n",
    "        pair[0]: 'word',\n",
    "        pair[1]: 'probability'\n",
    "    })\n",
    "    pieces.append(subset)\n",
    "\n",
    "tall = pd.concat(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "tall.to_csv('../clean/edge_word_topic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "    [0, 'Entertainment'],\n",
    "    [1, 'Sensory Fusion + Spanish)'],\n",
    "    [2, 'Emotional Timeframe'],\n",
    "    [3, 'Literary Airwaves + French'],\n",
    "    [4, 'Spirituality + Spanish'],\n",
    "    [5, 'Revolution + Spanish'],\n",
    "    [6, 'Twilight Narratives'],\n",
    "    [7, 'Dime Quieres + English'],\n",
    "    [8, 'Country Daydream (Names)'],\n",
    "    [9, 'Emotional Outburst (Explicit)'],\n",
    "    [10, 'Dale'],\n",
    "    [11, 'Doja'],\n",
    "    [12, 'Prende Energetico'],\n",
    "    [13, 'Lil Blossom'],\n",
    "    [14, 'Troubled Tunes'],\n",
    "    [15, 'Crimson Infusion'],\n",
    "    [16, 'Eloquent'],\n",
    "    [17, 'Ticket to Tenderness'],\n",
    "    [18, 'Diste la Verdad'],\n",
    "    [19, 'Watermelon Sugar']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../raw/track_keyword_occurences.csv').dropna()[['sid','word', 'occurence']].to_csv('../clean/edge_word_track.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
